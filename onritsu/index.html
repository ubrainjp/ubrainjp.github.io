<!DOCTYPE html>
<html lang="jp">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>純正律・平均律と音色および機能和声についての考察</title>
    <style>
      body { max-width: 800px;}
      #kotei { width: 100%; position: sticky; top: 5px; z-index: 10; background-color: white;}
      table { width: 100%; background-color: #dde39c; padding: 5px;}
      input { width: 100%;}
      canvas { background-color: lightgrey; width: 100%; height: 50px;}
      .midashi { background-color: #3F51B5; color: wheat; font-size: 1.5em; padding-left: 0.5em;}
      .indent { text-indent: -1em; margin-left: 1em;}
      .imgPlay, .imgStop { position: relative; top: 0.2em;}
      #footer { width: 100%; text-align: center; font-size: 0.8em; }
    </style>
</head>
<body>
    <div class="midashi">
      純正律・平均律と音色および機能和声についての考察
    </div>
    <div class="naiyou">
      <p><b><u>※GoogleChromeをご使用ください（Safariではパラメーターが正常に動作しません）</u></b></p>
      <p>年代を問わず純正律への関心の高まりは素晴らしいことですが、昨今はSNSでも純正律信仰とも言えるような誤った情報での啓発が多く気がかりになっています。</p>
      <p>バロックおよび古典派以降の作品は、平均律による機能和声で作曲されているので、純正律の乱用は横の繋がりを破壊した演奏になりがちです。</p>
      <p>純正律は基音（倍音を含まない）のみの音での理論が一人歩きすることに問題があります。
        実際の楽器の音や声には複雑な倍音が含まれており、特にプロのフォルテで響かせた音色の場合には倍音同士の干渉により、必ずしも純正律が有効には働きません。</p>
      <p>この理解の不足が、一部の教育現場などでは純正律を追求するあまり、個々の響きがないがしろの演奏になっている温床と考えます。</p>
      <p>このような話をすると、今度は逆に”音程合わせ不要論”飛躍する論調も現れますが、そうではありません。
        むしろ、平均律の響きの方が”うなり”の有無だけでは捉えられないので、より繊細な耳を養う必要があります。</p>
      <p>しばしば、純正律派と平均律派で対立のような論争に発展します。その背景にも、音色（響き）の無理解が関係していると思われます。</p>
      <p>まだ、音色との関係を扱った資料は多くないので、シンセサイザーで倍音の構成を変更できる実験装置を用いて、実験と解説を試みてみたいと思います。</p>
      <p>また、機能和声についての簡単な解説も合わせて行います。</p>
    </div>

    <div id="kotei">
      <table>
        <tr><td>倍音:&nbsp;<span id="modulationDepthValue">0</span></td></tr>
        <tr><td><input type="range" id="modulationDepth" min="0" max="1000" step="1" value="0"></td></tr>
        <tr><td>ピッチズレ:&nbsp;<span id="modulationDepthValue2">0</span>cent</td></tr>
        <tr><td><input type="range" id="modulationDepth2" min="0" max="50" step="1" value="0"></td></tr>
        <tr><td>純正律(0)-平均律(1):&nbsp;<span id="just2averageValue">1</span></td></tr>
        <tr><td><input type="range" id="just2average" min="0" max="1" step="0.1" value="1"></td></tr>
      </table>
      <!--Modulator Frequency: <input type="range" id="modulatorFrequency" min="1" max="20" step="0.001" value="1.1"><span id="modulatorFrequencyValue">1.1</span><br>-->
      <canvas id="spectrumCanvas" width="800" height="200"></canvas>
    </div>
    <p><b><u>※連続的に波形を変化させているため、位相差によるノイズが発生する場合があります。
      大音量での再生には注意をお願いいたします。再度、倍音（音色）を変更したり、再生しなおすと解消します。</u></b></p>
    <hr>
   
    <div class="midashi">
      <img class="imgPlay" src="" alt="Play" onclick="playChord('waon')">和音　
      <img class="imgPlay" src="" alt="Play" onclick="playChord('onlyC')">単音　
      <img class="imgStop" src="" alt="Stop" onclick="pauseAudio()">停止
    </div>
    <div class="naiyou indent">
      <p>まず、最初に単独和音での検証をしていきます。</p>
      <p>・倍音が”0”の状態で”<u>和音</u>”を再生してください。この状態で純正律と平均律の和音の響きの差を確認してみましょう。
      平均律の”うなり”も聴き比べないとわからないのではないでしょうか。ほとんどの人が比較なしに”平均律”を”純正律”と言われれば信じるでしょう。</p>
      <p>・”平均律”の状態で、倍音を少しずつ増やしていってみてください。音色によって”うなり”方にも変化が現れます。</p>
      <p>・次に”純正律”の状態で、倍音を少しずつ増やしていってみてください。音色によっては和音に聴こえずらかったり、かえって濁って聴こえてしまいます。
        音色によっては、必ずしも純正律が美しいとは言えないのです。</p>
      <p>では、”うなり”とピッチのズレによって生じる”濁り”とは何が違うのでしょうか。</p>
      <p>・倍音を”0”にした状態で”<u>単音</u>”を再生してください。”ピッチズレ”を少しずつ増やしていくと、周期的に”無音”になる瞬間があることが確認できます。
        これがピッチがズレると音が引っ込んで聴こえてしまう原因です。このような大きすぎる”うなり”を一般的には”濁り”と呼んでいます。</p>
      <p>・ピッチがズレた状態で、”和音”を様々な音色で（倍音を変えながら）再生してみましょう。
        ピッチのズレ方によっては和音としては破綻してしまいますが、意外にも綺麗に聴こえるのではないでしょうか。
        但し、これは単独の和音で聴いているからです。シンセサイザーなどでは、この”うなり”を効果的に利用しています。
        しかし、音楽として横の繋がりを持った途端に、やはり不都合が生じてしまいます。</p>
    </div>

    <div class="midashi">
      <img class="imgPlay" src="" alt="Play" onclick="playChord('canon')">カノン進行（Ⅰ-Ⅴ-Ⅵm-Ⅲm-Ⅳ-Ⅰ-Ⅳ-Ⅴ）　
      <img class="imgStop" src="" alt="Stop" onclick="pauseAudio()">停止
    </div>
    <div class="naiyou indent">
      <p>・作曲されたのは17世紀のバロック時代とされていますが、中世/ルネサンス様式を色濃く残しており現在でも根強い人気の和声進行です。</p>
      <p>・Ⅰ度/Ⅲ度/Ⅳ度/Ⅴ度/Ⅵ度のみで構成されており、純正律では響きが破綻してしまうⅡ度/Ⅶ度および7th系の4音構成の和音は使用されていません。</p>
      <p>・純正律と平均律それぞれに趣があるので、音色も変化させながら聴き比べてみましょう。</p>
      <p>・純正律も全くうなりが無いわけではありません。
        特にメジャーコードとマイナーコードの違いやボイシング（和音の転回形）の違いによって、”うなり”に変化が生じます。</p>
      <p>・倍音構成が複雑な音色ほど、倍音同士の干渉によって”うなり”が生じやすくなります。
        特に600以上の音色では、純正律の方が和音ごとの”うなり”の差が大きくなる影響を受けてしまい、横の流れに違和感が生じてしまいます。</p>
      <p>・純正律と平均律の中間値でも聴いてみてください。倍音を抑えて純正律に寄せた方が良い音色、倍音を響かせて平均律に寄せた方が良い音色が存在します。
        優れた演奏家は、ピッチだけでなく音色もコントロールして、縦の響きと横の流れを両立させる演奏をしているのです。</p>
    </div>

    <div class="midashi">
      <img class="imgPlay" src="" alt="Play" onclick="playChord('25')">Ⅵm-Ⅱm7-Ⅴ7-Ⅰ　
      <img class="imgStop" src="" alt="Stop" onclick="pauseAudio()">停止
    </div>
    <div class="naiyou indent">
      <p>・ここからは平均律が優勢の世界に突入していきます。Ⅴ7（属7）を含む和声進行を原則として純正律で演奏してはいけません。</p>
      <p>・”平均律”で音色を変えながら、以下のポイントを意識しながら聴いてみてください。</p>
      <p>・Ⅴ7（ドミナント）での”うなり”が最も小刻みになり緊張感をもたらします。続くⅠ（トニック）で”うなり”が”ゆらぎ”のように落ち着きます。
        この”うなり”の変化を利用した終止形（不安定→安定への変化）が、現在の音楽に続く機能和声の原点です。</p>
      <p>・純正律ではどう聴こえるでしょうか。和音間での”うなり”の差が大きくなりすぎて、横の流れの連続感が損なわれてしまいます。
        （ドミナントの”うなり”がトニックで急に全く消えたりするのは不自然です。）
        その為、実際の演奏では時として、アタックの瞬間は平均律でⅠ（トニック）に入り、音量と倍音を減衰させながら純正律に近づけるような操作も行われます。</p>
      <p>・ピッチのズレによっても、意図した”うなり”の差が損なわれてしまいます。</p>
      <p>・日本では雅楽などにもみられるよう、古来より”うなり”を利用した演奏が行われていました。
        西洋では17世紀に”うなり”を利用した機能和声の時代が訪れ、それまでの均整と調和のとれたルネサンス様式に対して、バロック様式（ゆがんだ真珠）と呼ばれるようになりました。</p>
      <p>・Ⅴ7（属7）は減5度（丁度1オクターブの半分の距離）が含まれており、数学的計算によって作り出された平均律の特徴的な和音です。
        また、その響きからも中世/ルネサンス期までは”悪魔の音程”として禁忌とされていました。
        しかし、現在に続く音楽では、この減5度抜きには多彩な躍動感を伴った表現を説明することができません。</p>
    </div>

    <div class="midashi">
      <img class="imgPlay" src="" alt="Play" onclick="playChord('onlyA')">Ⅵm-Ⅶm7-5-Ⅲm7-ⅠM7-ⅣM7-Ⅱm7-Ⅴ7-Ⅰ　
      <img class="imgStop" src="" alt="Stop" onclick="pauseAudio()">停止
    </div>
    <div class="naiyou indent">
      <p>・純正律率では禁忌の、Ⅱ度/Ⅶ度および4音構成の和音で構成された進行です。</p>
      <p>・純正律では和音ごとにウネリがバラバラで横の繋がりが全く意識できません。</p>
      <p>・クラシックでも普通に使われている進行で、特段ポップス的ということではありません。</p>
      <p>・平均律の美しさが感じ取れる和声進行の1例です。平均律の響きを純正律として紹介されたら、疑わない人も多いと思います。
        純正律と思っていたアカペラの響きも、実は平均律であることが多いです。</p>
      <p>・実はこのフレーズは、倍音を絞った音色（100前後）に限り純正律でも綺麗に聴こえます。但し、ここでも音色に制約が生じることに注目してください。</p>
      <p>・これが純正律と平均律のどちらで演奏するかで大論争に発展する要因とも考えます。
        私は機能感を無視した純正律での演奏には否定的ですが、純正律が好みという方が多いことも理解はできます。
        そこには、実は音色の関係性を無視しては語れない背景が置き去りにされています。</p>
      <p>・バロック以降、機能和声の特徴を活かすように、楽器の開発も歌唱法も平均律でより美しくように進化してきました。
        ピアノという楽器が（開発された年代的にも）最も良い例で、まさに”うなり”を利用して鐘を打った時のような荘厳な響きを作りだしています。</p>
      <p>・純正律（古楽）への憧れは現在でも継承され、様々なアプローチが行われていることも尊いことです。
        しかし、それが平均律の否定となっては、身近な音楽に触れる喜びも先人たちへのリスペクトも失ってしまうことになり、非常に悲しい事と思います。</p>
      <br>
      <p>★ルネサンス様式の純正律（実際には純正律に近い音律で演奏されていた）時代には、音色/和音/ハーモナイズにたくさんの制約を受けながら作曲/演奏に注ぎ込んだ先人の情熱が垣間見えます。
        また、平均律（実際の演奏には様々なアプローチがある）時代には、制約から解き放たれ次々と新たな理論を構築してきた先人たちの更なる情熱が伝わります。
        平均律によって解き放たれた制約には”音色”という大きな要素もあることにも、ご関心を持っていただければ幸いです。
      </p>
    </div>
    <br>

    <div id="footer">
      ©u-brain.jp<br/>
      <a href="mailto:ubrain.jp@gmail.com?subject=ChordApp">ubrain.jp@gmail.com</a>
    </div>

    <!--<button id="pauseButton">Stop</button>
    <br>
    <button onclick="playChord('low')">low</button>
    <button onclick="playChord('mid')">mid</button>
    <button onclick="playChord('high')">high</button>
    <button onclick="playChord('waon')">waon</button>
    <button onclick="playChord('onlyC')">onlyC</button>
    <button onclick="playChord('amen')">amen</button>
    <button onclick="playChord('25')">25</button>
    <button onclick="playChord('onlyA')">canon</button>
    <br>-->

    <script>
        const imgPlay = document.getElementsByClassName("imgPlay");
        for (let i = 0; i < imgPlay.length; i++) {
          imgPlay[i].src = "data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzAiIGhlaWdodD0iMzAiIHZpZXdCb3g9IjAgMCAzMCAzMCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTE1IDBDMjMuMjgzMiAwIDMwIDYuNzE2ODIgMzAgMTVTMjMuMjgzMiAzMCAxNSAzMFMwIDIzLjI4MzIgMCAxNVM2LjcxNjgyIDAgMTUgMFoiIGZpbGw9IiMwMEZGRjAiLz4KPHBhdGggZD0iTTEwLjUgMjQuMjI0NFY1Ljc3NTU4QzEwLjUgNS4yMTg1NiAxMS4xMTgzIDQuOTEwMDUgMTEuNjAzNSA1LjIzMDY0TDI0LjIyOTkgMTQuNDc1NUMyNC43MTIxIDE0Ljc5NzYgMjQuNzE0NSAxNS4yMDI0IDI0LjIyODkgMTUuNTI0NUwxMS42MDM1IDI0Ljc2OTVDMTEuMTE4MyAyNS4wODkxIDEwLjUgMjQuNzc4NDQgMTAuNSAyNC4yMjQ0WiIgZmlsbD0id2hpdGUiLz4KPC9zdmc+Cg==";
        }
        const imgStop = document.getElementsByClassName("imgStop");
        for (let i = 0; i < imgStop.length; i++) {
          imgStop[i].src = "data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzAiIGhlaWdodD0iMzAiIHZpZXdCb3g9IjAgMCAzMCAzMCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTE1IDBDMjMuMjgzMiAwIDMwIDYuNzE2ODIgMzAgMTVTMjMuMjgzMiAzMCAxNSAzMFMwIDIzLjI4MzIgMCAxNVM2LjcxNjgyIDAgMTUgMFoiIGZpbGw9IiMwMEZGRjAiLz4KPHJlY3QgeD0iMTEiIHk9IjExIiB3aWR0aD0iOCIgaGVpZ2h0PSI4IiBmaWxsPSJ3aGl0ZSIvPgo8L3N2Zz4K";
        }

        const AudioContext = window.AudioContext || window.webkitAudioContext;
        const audioContext = new AudioContext();

        /*const waveData = new Float32Array(1024); 
        for (let i = 0; i < waveData.length; i++) {
          const phase = (i / waveData.length) * Math.PI * 2; 
          waveData[i] = Math.sin(phase);
        }
        const waveTable = audioContext.createPeriodicWave(waveData, waveData);*/

        const analyser = audioContext.createAnalyser();
        analyser.fftSize = 4096;
        const bufferLength = analyser.frequencyBinCount;
        const dataArray = new Uint8Array(bufferLength);

        const gainNode = audioContext.createGain();
        gainNode.gain.value = 0.0;
        const gainNode2 = audioContext.createGain();
        gainNode2.gain.value = 0.0;

        const gainNodeCarrier1_1 = audioContext.createGain();
        gainNodeCarrier1_1.gain.value = 0.0;
        const gainNodeCarrier1_2 = audioContext.createGain();
        gainNodeCarrier1_2.gain.value = 0.0;
        const gainNodeCarrier2 = audioContext.createGain();
        gainNodeCarrier2.gain.value = 0.0;

        const lowpassFilter = audioContext.createBiquadFilter();
        lowpassFilter.type = 'highpass';
        lowpassFilter.frequency.value = 100;
        //lowpassFilter.Q.value = 10;
        lowpassFilter.connect(gainNode);
        //lowpassFilter.connect(analyserGain);

        gainNodeCarrier1_1.connect(lowpassFilter);
        gainNodeCarrier1_2.connect(lowpassFilter);
        gainNodeCarrier2.connect(lowpassFilter);
        gainNode.connect(gainNode2);
        gainNode2.connect(audioContext.destination);
        gainNode2.connect(analyser);

        let carrier = [];
        let carrier2 = [];
        let modulator = [];
        let modulatorGain = [];
        let modulator2 = [];
        let modulatorGain2 = [];

        function createOscs() {
          for (let i = 0; i < 4; i++) {
            carrier[i] = audioContext.createOscillator();
            carrier2[i] = audioContext.createOscillator();
            modulator[i] = audioContext.createOscillator();
            modulatorGain[i] = audioContext.createGain();
            modulator2[i] = audioContext.createOscillator();
            modulatorGain2[i] = audioContext.createGain();

            carrier[i].type = 'sine'; //.setPeriodicWave(waveTable);
            carrier[i].frequency.value = 0;
            carrier2[i].type = 'sine';
            carrier2[i].frequency.value = 0;

            modulator[i].type = 'sine';
            modulator[i].frequency.value = 0;
            modulatorGain[i].gain.value = 0;
            modulator2[i].type = 'sine';
            modulator2[i].frequency.value = 0;
            modulatorGain2[i].gain.value = 0;

            modulator[i].connect(modulatorGain[i]);
            modulatorGain[i].connect(carrier[i].frequency);
            modulator2[i].connect(modulatorGain2[i]);
            modulatorGain2[i].connect(carrier2[i].frequency);

            if (i == 0) {
              carrier[i].connect(gainNodeCarrier1_1);
            } else {
              carrier[i].connect(gainNodeCarrier1_2);
            }
            carrier2[i].connect(gainNodeCarrier2);
            //carrier[i].connect(analyserGain);

            const currentTime = audioContext.currentTime;
            carrier[i].start(currentTime);
            carrier2[i].start(currentTime);
            modulator[i].start(currentTime);
            modulator2[i].start(currentTime);
          }
        }

        const chords = {
          "low":[[48,0,4,7,12,1,1,1,1]],
          "mid":[[60,0,4,7,12,1,1,1,1]],
          "high":[[72,0,4,7,12,1,1,1,1]],
          "waon":[[60,0,4,7,12,0.5,1,1,1]],
          "onlyC":[[60,0,0,0,0,1,1,1,1]],
          "amen":[[60,0,4,7,12,0.5,1,1,1],[60,5,5,9,12,0.5,1,1,1],[60,0,4,7,12,0.5,1,1,1]],
          "25":[[60,9,4,9,12,0.5,1,1,1],[60,2,5,9,12,0.5,1,1,1],[60,7,2,5,11,0.5,1,1,1],[60,0,4,7,12,0.5,1,1,1]],
          "25+":[[60,9,4,9,12,0.5,1,1,1],[62,0,3,7,10,0.5,1,1,1],[67,0,7,10,4,0.5,0.5,0.5,1],[60,0,4,7,12,0.5,1,1,1]],
          "canon":[[60,0,7,12,4,1,1,1,2],[60,7,7,11,2,0.5,1,1,2],[60,9,4,9,12,0.5,1,1,1],[60,4,4,7,11,0.5,1,1,1],
          [60,5,0,5,9,0.5,1,1,1],[60,0,0,4,7,0.5,1,1,1],[60,5,0,5,9,0.5,1,1,1],[60,7,2,7,11,0.5,1,1,1]],
          "onlyA":[[60,9,0,4,9,0.5,1,1,1],[60,11,2,5,9,0.5,1,1,1],[60,4,11,2,7,0.5,0.5,1,1],[60,0,11,4,7,0.5,0.5,1,1],
          [60,5,0,4,9,0.5,1,1,1],[60,2,0,5,9,0.5,1,1,1],[60,7,2,5,11,0.5,1,1,1],[60,0,4,7,12,0.5,1,1,1]],
        }

        function updateChord() {
          let modulationDepth = parseFloat(document.getElementById('modulationDepth').value);
          let just2average = parseFloat(document.getElementById('just2average').value);
          let modulationDepth2 = parseFloat(document.getElementById('modulationDepth2').value);
          document.getElementById('modulationDepthValue').textContent = modulationDepth;
          document.getElementById('modulationDepthValue2').textContent = modulationDepth2;
          document.getElementById('just2averageValue').textContent = just2average;

          let chord = JSON.parse(JSON.stringify(nowChord[nowNo]));
          chord[0] = noteNo2hz(chord[0]);
          //console.log(chord)
          const currentTime = audioContext.currentTime;
          let chordx = [
            xhz(chord[0], chord[1], just2average) * chord[5], 
            xhz(chord[0], chord[2], just2average) * chord[6],
            xhz(chord[0], chord[3], just2average) * chord[7], 
            xhz(chord[0], chord[4], just2average) * chord[8]
          ];
          carrier[0].frequency.setValueAtTime(chordx[0], currentTime);
          carrier[1].frequency.setValueAtTime(chordx[1], currentTime);
          carrier[2].frequency.setValueAtTime(chordx[2], currentTime);
          carrier[3].frequency.setValueAtTime(chordx[3], currentTime);
          //carrier[0].frequency.value = chordx[0];
          //carrier[1].frequency.value = chordx[1];
          //carrier[2].frequency.value = chordx[2];
          //carrier[3].frequency.value = chordx[3];
          if (chord[1] == chord[2] && chord[5] == chord[6]) {
            gainNodeCarrier1_1.gain.setValueAtTime(gainNodeCarrier1_1.gain.value, currentTime);
            gainNodeCarrier1_1.gain.linearRampToValueAtTime(1, currentTime + 0.05);
            gainNodeCarrier1_2.gain.setValueAtTime(gainNodeCarrier1_2.gain.value, currentTime);
            gainNodeCarrier1_2.gain.linearRampToValueAtTime(0, currentTime + 0.05);
          } else {
            gainNodeCarrier1_1.gain.setValueAtTime(gainNodeCarrier1_1.gain.value, currentTime);
            gainNodeCarrier1_1.gain.linearRampToValueAtTime(1, currentTime + 0.05);
            gainNodeCarrier1_2.gain.setValueAtTime(gainNodeCarrier1_2.gain.value, currentTime);
            gainNodeCarrier1_2.gain.linearRampToValueAtTime(1, currentTime + 0.05);
          }

          for (let i = 0; i < 4; i++) {
            modulator[i].frequency.setValueAtTime(chordx[i], currentTime);
            modulatorGain[i].gain.setValueAtTime(modulationDepth, currentTime);
            //modulator[i].frequency.value = chordx[i];
            //modulatorGain[i].gain.value = modulationDepth;
            if (modulationDepth2 == 0) {
              gainNode2.gain.setValueAtTime(gainNode2.gain.value, currentTime);
              gainNode2.gain.linearRampToValueAtTime(2, currentTime + 0.05);
              gainNodeCarrier2.gain.setValueAtTime(gainNodeCarrier2.gain.value, currentTime);
              gainNodeCarrier2.gain.linearRampToValueAtTime(0, currentTime + 0.05);
            } else {
              gainNode2.gain.setValueAtTime(gainNode2.gain.value, currentTime);
              gainNode2.gain.linearRampToValueAtTime(1, currentTime + 0.05);
              if (chord[1] == chord[2] && chord[5] == chord[6]) {
                gainNodeCarrier2.gain.setValueAtTime(gainNodeCarrier2.gain.value, currentTime);
                gainNodeCarrier2.gain.linearRampToValueAtTime(0.25, currentTime + 0.05);
              } else {
                gainNodeCarrier2.gain.setValueAtTime(gainNodeCarrier2.gain.value, currentTime);
                gainNodeCarrier2.gain.linearRampToValueAtTime(1, currentTime + 0.05);
              }
            }
            let carrier2Freq = chordx[i] * (2 ** (modulationDepth2/1200))
            carrier2[i].frequency.setValueAtTime(carrier2Freq, currentTime);
            modulator2[i].frequency.setValueAtTime(carrier2Freq, currentTime);
            modulatorGain2[i].gain.setValueAtTime(modulationDepth, currentTime);
            //carrier2[i].frequency.value = carrier2Freq;
            //modulator2[i].frequency.value = carrier2Freq;
            //modulatorGain2[i].gain.value = modulationDepth;
          }
        }

        function xhz(root, deg, ja) {
          const just = [1, , 9/8, 6/5, 5/4, 4/3, , 3/2, 8/5, 5/3, 9/5, 15/8, 2];
          const justCent = [0, , 4, 16, -14, -2, , 2, 14, -16, 18, -12, 0];
          if (ja == 0) {
            var hz = root * just[deg];
          } else {
            ja = (1 - ja) * justCent[deg] / 100;
            var hz = root * (2 ** ((deg + ja) / 12));
          }
          //console.log(hz);
          return hz;
        } 

        function noteNo2hz(midiNo) {
          const no = (midiNo - 69);
          const hz = 440 * 2 ** (no / 12);
          return hz;
        }

        let nowPlaying = false;
        let nowChord = [];
        let nowNo = -1;
        function playChord(_cho) {
          if (nowPlaying) { 
            pauseAudio(_cho);
            return false;
          }
          createOscs();
          nowPlaying = true;
          nowChord = JSON.parse(JSON.stringify(chords[_cho]));
          nowNo = 0;
          updateChord();
          if (nowChord.length > 1) {
            timeId = setTimeout(nextChord, 2000);
          }
          //audioContext.resume();
          const currentTime = audioContext.currentTime;
          gainNode.gain.setValueAtTime(gainNode.gain.value, currentTime);
          gainNode.gain.linearRampToValueAtTime(0.1, currentTime + 0.01);
        }

        let timeId;
        function nextChord() {
          if (nowChord[nowNo + 1]) {
            nowNo++;
          } else {
            nowNo = 0;
          }
          updateChord();
          timeId = setTimeout(nextChord, 1500);
        }

        function pauseAudio(_cho) {
          const currentTime = audioContext.currentTime;
          gainNode.gain.setValueAtTime(gainNode.gain.value, currentTime);
          gainNode.gain.linearRampToValueAtTime(0, currentTime + 0.1);
          gainNodeCarrier1_1.gain.setValueAtTime(gainNodeCarrier1_1.gain.value, currentTime);
          gainNodeCarrier1_1.gain.linearRampToValueAtTime(0, currentTime + 0.1);
          gainNodeCarrier1_2.gain.setValueAtTime(gainNodeCarrier1_2.gain.value, currentTime);
          gainNodeCarrier1_2.gain.linearRampToValueAtTime(0, currentTime + 0.1);
          gainNodeCarrier2.gain.setValueAtTime(gainNodeCarrier2.gain.value, currentTime);
          gainNodeCarrier2.gain.linearRampToValueAtTime(0, currentTime + 0.1);
          //audioContext.suspend();
          clearTimeout(timeId);
          nowPlaying = false;
          nowChord = [];
          nowNo = -1;
          for (let i = 0; i < 4; i++) {
            carrier[i].stop(currentTime + 0.11);
            carrier2[i].stop(currentTime + 0.11);
            modulator[i].stop(currentTime + 0.11);
            modulator2[i].stop(currentTime + 0.11);
          }
          carrier = [];
          carrier2 = [];
          modulator = [];
          modulatorGain = [];
          modulator2 = [];
          modulatorGain2 = [];
          if (_cho) { setTimeout(playChord, 150, _cho); }
        }

        function getFrequency(index, sampleRate, fftSize) {
            return index * (sampleRate / fftSize);
        }
        function logScale(index, sampleRate, fftSize) {
            const frequency = getFrequency(index, sampleRate, fftSize);
            const minFrequency = 20;
            const maxFrequency = 20000;
            const minLog = Math.log10(minFrequency);
            const maxLog = Math.log10(maxFrequency);
            const logFreq = Math.log10(frequency);
            return (logFreq - minLog) / (maxLog - minLog);
        }
        function drawSpectrum() {
            const canvas = document.getElementById('spectrumCanvas');
            const canvasCtx = canvas.getContext('2d');

            requestAnimationFrame(drawSpectrum);

            analyser.getByteFrequencyData(dataArray);

            canvasCtx.clearRect(0, 0, canvas.width, canvas.height);

            const minFrequency = 20;
            const maxFrequency = 20000;
            const minLog = Math.log10(minFrequency);
            const maxLog = Math.log10(maxFrequency);
            const barWidth = 2;

            for (let i = 0; i < bufferLength; i++) {
                const barHeight = dataArray[i];
                const logPosition = logScale(i, audioContext.sampleRate, analyser.fftSize);
                const x = logPosition * canvas.width;

                canvasCtx.fillStyle = 'rgb(' + (barHeight + 100) + ',50,50)';
                canvasCtx.fillRect(x, canvas.height - barHeight / 2, barWidth, barHeight / 2);
            }

            const labelFrequencies = [20, 50, 100, 200, 500, 1000, 2000, 5000, 10000, 20000];
            canvasCtx.fillStyle = 'white';
            canvasCtx.textAlign = 'center';
            for (const freq of labelFrequencies) {
                const logFreq = Math.log10(freq);
                const logPosition = (logFreq - minLog) / (maxLog - minLog);
                const x = logPosition * canvas.width;
                canvasCtx.fillText(freq + ' Hz', x, canvas.height - 10);
            }
        }
        drawSpectrum();

        document.getElementById('modulationDepth').addEventListener('input', updateChord);
        document.getElementById('modulationDepth2').addEventListener('input', updateChord);
        document.getElementById('just2average').addEventListener('input', updateChord);
        //document.getElementById('pauseButton').addEventListener('click', pauseAudio);
    </script>
</body>
</html>
